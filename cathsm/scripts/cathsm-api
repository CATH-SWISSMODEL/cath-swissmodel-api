#!/usr/bin/env python3

"""
CLI tool to search for template structures for modelling
"""

# core
import argparse
import logging
import os
import re
import string
import tempfile
from multiprocessing import Pool

# non-core
import requests
from Bio import SeqIO

# local
from cathsm.apiclient import managers, models, clients

DEFAULT_MAX_WORKERS = 5

# logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(message)s',
    datefmt='%d-%m-%Y %H:%M:%S')
LOG = logging.getLogger(__name__)

CATHAPI_OPENAPI_URL = 'http://{:api1_base}/swagger/?format=openapi'
SM_OPENAPI_URL = 'http://{:api2_base}/swagger/?format=openapi'

# CLI args
parser = argparse.ArgumentParser()
parser.add_argument('--in', '-i', dest='infile', type=str, required=True,
                    help='query sequence (FASTA)')
parser.add_argument('--outdir', '-o', dest='outdir', type=str, required=True,
                    help='output directory')
parser.add_argument('--user', '-u', dest='user', type=str, required=True,
                    help='API user')
parser.add_argument('--max_workers', dest='max_workers', type=int, default=DEFAULT_MAX_WORKERS,
                    help='Number of jobs to process in parallel')
parser.add_argument('--api1_base', dest='api1_base', type=str, required=False,
                    default=None,
                    help='override base url for API1')
parser.add_argument('--api2_base', dest='api2_base', type=str, required=False,
                    default=None,
                    help='override base url for API2')

parser.add_argument('--startseq', dest='startseq', type=int, default=1, 
                    help='choose the sequence to start from') 

def process_sequence(job_args):
    """Processes a query sequence"""

    seq_count, seq_id, seq_str, outdir, user_id = list(job_args)
    os.chdir(outdir)

    log = logging.getLogger('process_sequence_{}'.format(seq_count))
    fh = logging.FileHandler('process.log')
    fh.setLevel(logging.INFO)
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    fh.setFormatter(formatter)
    log.addHandler(fh)

    log.info("SEQUENCE {}: {} ({} residues)".format(
        seq_count, seq_id, len(seq_str)))

    char_width = 80
    seq_lines = [seq_str[i:i+char_width]
                 for i in range(0, len(seq_str), char_width)]
    for seq_line in seq_lines:
        log.info("{}".format(seq_line))

    log_br(log)
    log.info("Searching for template structures ... ")

    api1submit = models.SubmitSelectTemplate(
        query_id=seq_id, query_sequence=seq_str)

    api1 = managers.CathSelectTemplateManager(
        base_url=args.api1_base,
        submit_data=api1submit,
        api_user=user_id,
        logger=log,
    )
    api1.run()
    task_uuid = api1.task_uuid

    log_br(log)

    # swagger_app, swagger_client = api1.api_client.get_swagger()
    # hit_operation_id = 'select-template_resolved_hits_read'  # TODO: this is nasty
    # req, resp = swagger_app.op[hit_operation_id](
    #     uuid=api1.task_uuid)
    # req.produce('application/json')
    # hits = swagger_client.request((req, resp)).data

    # TODO: abstract this away to clients / managers / swagger? ...
    api1_base = args.api1_base
    headers = {'Authorization': 'Token ' + api1.api_token}

    log.info("Getting resolved hit info ...")
    hits_url = '{api1_base}/api/select-template/{task_uuid}/resolved_hits'.format(
        api1_base=api1_base, task_uuid=task_uuid)
    log.info("GET %s", hits_url)
    resp = requests.get(hits_url, headers=headers)
    resp.raise_for_status()
    hits = resp.json()
    log.info("  ... retrieved %s resolved hits", len(hits))
    log_br(log)

    # hits = managers.GetSelectTemplateHits(task_uuid=api1.task_uuid)
    # hits = api1.funfam_resolved_scan_hits()

    for hit_count, hit in enumerate(hits, 1):

        log.info("SEQUENCE %s, HIT %s [%s]: FunFam '%s': %s",
                 seq_count, hit_count, hit['query_range'], hit['ff_id'], hit['ff_name'])

        log.info("Getting template alignments ...")
        aln_url = '{api1_base}/api/select-template/hit/{hit_uuid}/alignments'.format(
            api1_base=api1_base, hit_uuid=hit['uuid'])
        log.info("GET %s", aln_url)
        resp = requests.get(aln_url, headers=headers)
        resp.raise_for_status()
        alns = resp.json()
        log.info("  ... retrieved %s template alignments", len(alns))
        log_br(log)

        if not alns:
            log.warning('Found no valid template alignments from hit %s (no CATH domains?). Skipping.', hit['ff_id'])
            continue

        log_prefix = 'HIT{}'.format(hit_count)
        aln = alns[0]

        log.info("%s: Modelling region against template %s, %s (offset %s) ... ",
                 log_prefix, aln['pdb_id'], aln['auth_asym_id'], aln['template_seqres_offset'])

        log.info("%10s %8s: %s", 'QUERY',
                 hit['query_range'],
                 aln['target_sequence'], )
        log.info("%10s %8s: %s", '{}, {}'.format(aln['pdb_id'], aln['auth_asym_id']),
                 aln['template_seqres_offset'],
                 aln['template_sequence'])
        log_br(log)

        api2submit = models.SubmitAlignment(
            target_sequence=aln['target_sequence'],
            template_sequence=aln['template_sequence'],
            template_seqres_offset=aln['template_seqres_offset'],
            pdb_id=aln['pdb_id'],
            auth_asym_id=aln['auth_asym_id'],
        )

        pdb_out_id = re.sub('[\W]+', '', seq_id)

        api2 = managers.SMAlignmentManager(
            submit_data=api2submit,
            outfile="{}.pdb".format(pdb_out_id),
            api_user=user_id,
            logger=log,
        )
        api2.run()
        log_br(log)


def run(*, infile, outdir, max_workers, api_user, startseq=1):
    """Runs the main application"""

    LOG.info("Parsing sequences from %s", infile)
    log_hr()
    sequences = []
    for seq in SeqIO.parse(infile, "fasta"):
        LOG.info("SEQUENCE: '%s' (%d residues)",
                 seq.id, len(seq))
        sequences.extend([seq])

    re_safe = re.compile(r'[\W]+', re.UNICODE)
    process_args = []
    for seq_count, seq in enumerate(sequences[startseq-1:], startseq):

        safe_dirname = re_safe.sub('', seq.id)
        process_outdir = os.path.abspath(os.path.join(outdir, safe_dirname))

        if not os.path.exists(process_outdir):
            os.makedirs(process_outdir)

        process_args.extend([[seq_count, seq.id, seq.seq, process_outdir, api_user]])

    #with Pool(max_workers) as p:
    #    p.map(process_sequence, process_args)
    
    for pargs in process_args:
        process_sequence(pargs)

    LOG.info("DONE")


def log_br(log=None):
    if not log:
        log = LOG
    log.info('')


def log_hr(log=None):
    if not log:
        log = LOG
    log.info('')
    log.info('-'*80)
    log.info('')


if __name__ == '__main__':
    args = parser.parse_args()
    run(infile=args.infile, outdir=args.outdir, max_workers=args.max_workers, 
            api_user=args.user, startseq=args.startseq)
